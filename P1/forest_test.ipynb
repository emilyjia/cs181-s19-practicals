{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy as sp\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold\n",
    "def kfold(k, predictor, X):\n",
    "    kf = KFold(n_splits = k, random_state = 0)\n",
    "    count = 0\n",
    "    for trains, tests in kf.split(X):\n",
    "        x_train = X.iloc[trains, 1:-1]\n",
    "        y_train = X.iloc[trains, -1]\n",
    "        x_test = X.iloc[tests, 1:-1]\n",
    "        y_test = X.iloc[tests, -1]\n",
    "        predictor.fit(x_train, y_train)\n",
    "        predictions = predictor.predict(x_test)\n",
    "        count += np.sqrt(mean_squared_error(predictions, y_test))\n",
    "    return count/k\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test sets (assumes you have these in current working directory)\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set into X and y (removing first column containing IDs)\n",
    "X_train = train.iloc[:, 1:-1]\n",
    "y_train = train.iloc[:, -1]\n",
    "\n",
    "# Remove first column to make predictions\n",
    "X_test = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to compute RMSE\n",
    "def scoreRMSE(predictor, X, true_y):\n",
    "    predictions = predictor.predict(X)\n",
    "    return np.sqrt(mean_squared_error(predictions, true_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.027169137663525363\n",
      "2\n",
      "0.027079539239580064\n",
      "4\n",
      "0.027066751093652107\n"
     ]
    }
   ],
   "source": [
    "# tune min_leaf\n",
    "for min_leaf in [1,2,4, 6, 8, 10, 12, 15, 20]:\n",
    "    print min_leaf\n",
    "    rfr = RFR(n_estimators=50, min_samples_leaf=min_leaf)\n",
    "    print kfold(5, rfr, train)\n",
    "for min_leaf in [6,8,10]:\n",
    "    print min_leaf\n",
    "    rfr = RFR(n_estimators=50, min_samples_leaf=min_leaf)\n",
    "    print kfold(5, rfr, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training RMSE: ', 0.010238567468084216)\n"
     ]
    }
   ],
   "source": [
    "# Fit unregularized linear regression and see RMSE on training set\n",
    "\n",
    "# >>> regr = RandomForestRegressor(max_depth=2, random_state=0,\n",
    "# ...                              n_estimators=100)\n",
    "# >>> regr.fit(X, y)\n",
    "\n",
    "rfR = RFR(n_estimators=100, min_samples_leaf=1)\n",
    "rfR.fit(X_train, y_train)\n",
    "\n",
    "print (\"Training RMSE: \", scoreRMSE(rfR, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using linear regression model fitted above\n",
    "predictions = rfR.predict(X_test)\n",
    "\n",
    "# Format predictions to be compatible with Kaggle upload\n",
    "sample_submission = pd.DataFrame(data=predictions, columns=['Predicted'])\n",
    "sample_submission.insert(0, \"Id\", range(1, 1 + X_test.shape[0]))\n",
    "sample_submission['Id'] = sample_submission['Id'].astype(str)\n",
    "sample_submission.head()\n",
    "# Save predictions to .csv file for upload to Kaggle\n",
    "sample_submission.to_csv(\"rfr2000.csv\", index=False)\n",
    "\n",
    "# Save predictions to .csv file for upload to Kaggle\n",
    "sample_submission.to_csv(\"sample_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rfR.feature_importances_)\n",
    "featimp = [(feature, importance) for feature, importance in zip(X_train.columns, importances)]\n",
    "featimp = sorted(featimp, key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "0.07991096431842995\n",
      "0.13764876709783117\n",
      "0.18961021499353706\n",
      "0.22784413915442492\n",
      "0.26549583332384646\n",
      "0.2928338536446564\n",
      "0.3201569324283597\n",
      "0.34581825351223167\n",
      "0.36991628371175195\n",
      "0.393092466447579\n",
      "0.4126117949179578\n",
      "0.43186026826031054\n",
      "0.44993705276758345\n",
      "0.4673435908183174\n",
      "0.48367656961462174\n",
      "0.49877813786915753\n",
      "0.5117460699088983\n",
      "0.5231074120061423\n",
      "0.5341294953233564\n",
      "0.545031345715784\n",
      "0.5556273165645229\n",
      "0.5656178902146551\n",
      "0.5755825273159407\n",
      "0.5854691042005319\n",
      "0.5951558308410391\n",
      "0.6046481683429656\n",
      "0.6140023265458029\n",
      "0.6228857226959982\n",
      "0.631478023436093\n",
      "0.6400674034014762\n",
      "0.6482552634042883\n",
      "0.6562609516613919\n",
      "0.6638668681490998\n",
      "0.6714339901961427\n",
      "0.6781750999437189\n",
      "0.6848160414868039\n",
      "0.6912589125143355\n",
      "0.6971927411090463\n",
      "0.7031082249118669\n",
      "0.7089219226905774\n",
      "0.7146796275373197\n",
      "0.7203214393868185\n",
      "0.7259559571962219\n",
      "0.7314207297447991\n",
      "0.73660148807594\n",
      "0.7417145398071763\n",
      "0.7467158603157223\n",
      "0.751468184785936\n",
      "0.7561848059835785\n",
      "0.7608644917251207\n",
      "0.765225483219405\n",
      "0.7693821907616099\n",
      "0.7735322465695431\n",
      "0.7776661918737088\n",
      "0.7817597590301759\n",
      "0.7858111900443038\n",
      "0.7898455659663497\n",
      "0.7936456275934838\n",
      "0.7974379110475514\n",
      "0.8012298873023715\n",
      "0.8050201603523227\n",
      "0.8087429380741166\n",
      "0.8124602564412521\n",
      "0.8161303150127125\n",
      "0.8197324308335096\n",
      "0.8233310186973644\n",
      "0.8269138619078878\n",
      "0.8303905504882318\n",
      "0.8338628715127266\n",
      "0.8371167377551471\n",
      "0.8403539425001427\n",
      "0.8435501001291346\n",
      "0.8467359690070387\n",
      "0.8498574801766055\n",
      "0.8529689722612142\n",
      "0.856071265301251\n",
      "0.8591679520014902\n",
      "0.8620658831591255\n",
      "0.8649498018839802\n",
      "0.8677998411529815\n",
      "0.8706358615306867\n",
      "0.8734197902679521\n",
      "0.876203623411846\n",
      "0.8789540275403559\n",
      "0.8816146328695931\n",
      "0.8842292126931882\n",
      "0.88674075359394\n",
      "0.8891243015372108\n",
      "0.8915019658232514\n",
      "0.8938033144732918\n",
      "0.8961043892559918\n",
      "0.8983734881516742\n",
      "0.9006298133912539\n",
      "0.9028648134979179\n",
      "0.9050312252244198\n",
      "0.9071772482316617\n",
      "0.9093188885031173\n",
      "0.9114514734794673\n",
      "0.9135555621771052\n",
      "0.9156540622542648\n",
      "0.9177386899620444\n",
      "0.9197985714079402\n",
      "0.9218336675207097\n",
      "0.9238519027775463\n",
      "0.9258604243621241\n",
      "0.9278065213926731\n",
      "0.9297475450101587\n",
      "0.931603315984218\n",
      "0.9334035382832013\n",
      "0.9351809853677397\n",
      "0.9369419081638343\n",
      "0.9386740852933895\n",
      "0.9402608107959551\n",
      "0.9418003915326395\n",
      "0.943224538281788\n",
      "0.9446324100896487\n",
      "0.9460333047420059\n",
      "0.9474286017884354\n",
      "0.9487885202292924\n",
      "0.9501458209286999\n",
      "0.9514974948393586\n",
      "0.952833983500107\n",
      "0.9541672364820758\n",
      "0.9554961577023606\n",
      "0.9567905110796753\n",
      "0.9580800272408162\n",
      "0.9593459701396866\n",
      "0.9605559247883716\n",
      "0.9617630375268382\n",
      "0.962967823254644\n",
      "0.9641435621978683\n",
      "0.9652993135524056\n",
      "0.9664166120709884\n",
      "0.9675005831660103\n",
      "0.9685777378195872\n",
      "0.9696098529327883\n",
      "0.9706340169102503\n",
      "0.9716520973673036\n",
      "0.9726311369540865\n",
      "0.9736069032291924\n",
      "0.974575830185021\n",
      "0.9755401904935442\n",
      "0.976497900947644\n",
      "0.9774202217749045\n",
      "0.9782755136133897\n",
      "0.9791274691347387\n",
      "0.9799751922454837\n",
      "0.9807844185525268\n",
      "0.981590666997303\n",
      "0.9823824067768688\n",
      "0.9831567463238441\n",
      "0.9839113958942883\n",
      "0.9846434450253485\n",
      "0.9853612354312387\n",
      "0.986029928299927\n",
      "0.9866955791642152\n",
      "0.9873172737180255\n",
      "0.9879279852734458\n",
      "0.9885081813997897\n",
      "0.9890828638811466\n",
      "0.9896543591027225\n",
      "0.9901830754398392\n",
      "0.9907041961715239\n",
      "0.9911904853606409\n",
      "0.9916630237067402\n",
      "0.9921280767897458\n",
      "0.9925869640681829\n",
      "0.9930408483392075\n",
      "0.9934881878796633\n",
      "0.9939348994741486\n",
      "0.9943434174058506\n",
      "0.9947439620019046\n",
      "0.9951196642794822\n",
      "0.9954837463433416\n",
      "0.9958335188736874\n",
      "0.996156941782186\n",
      "0.9964754410601612\n",
      "0.9967742160213795\n",
      "0.9970680294315554\n",
      "0.9973545495706202\n",
      "0.9976275236637696\n",
      "0.9978946039198588\n",
      "0.9981527332160727\n",
      "0.9983899219607871\n",
      "0.9986049384699434\n",
      "0.9987965322932688\n",
      "0.998972622975019\n",
      "0.9991396492195026\n",
      "0.9992887185469956\n",
      "0.9994232449350299\n",
      "0.9995201232280331\n",
      "0.9996050776600359\n",
      "0.9996791031824431\n",
      "0.9997519847733108\n",
      "0.9998000819233813\n",
      "0.9998470772100245\n",
      "0.9998939783365038\n",
      "0.9999236259259008\n",
      "0.9999446647593738\n",
      "0.9999643938382132\n",
      "0.9999781406497175\n",
      "0.9999917408171747\n",
      "0.9999976534531445\n",
      "0.9999986775893881\n",
      "0.9999994115113562\n",
      "0.9999998156541609\n",
      "0.9999999616873678\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# List of features sorted from most to least important\n",
    "sorted_importances = [importance[1] for importance in featimp]\n",
    "sorted_features = [importance[0] for importance in featimp]\n",
    "print sum(sorted_importances)\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "for x in cumulative_importances:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the names of the most important features\n",
    "important_feature_names = [feature[0] for feature in featimp[0:49]]\n",
    "target = \"Target\"\n",
    "important_feature_names.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Feat 251', 'Feat 249', 'Feat 247', 'Feat 250', 'Feat 248', 'Feat 246', 'Feat 4', 'Feat 1', 'Feat 3', 'Feat 172', 'Feat 151', 'Feat 13', 'Feat 125', 'Feat 177', 'Feat 171', 'Feat 150', 'Feat 6', 'Feat 149', 'Feat 131', 'Feat 127', 'Feat 12', 'Feat 5', 'Feat 9', 'Feat 175', 'Feat 153', 'Feat 120', 'Feat 124', 'Feat 176', 'Feat 183', 'Feat 126', 'Feat 128', 'Feat 10', 'Feat 214', 'Feat 165', 'Feat 233', 'Feat 232', 'Feat 14', 'Feat 130', 'Feat 84', 'Feat 219', 'Feat 7', 'Feat 200', 'Feat 197', 'Feat 154', 'Feat 182', 'Feat 133', 'Feat 185', 'Feat 39', 'Feat 166', 'Target']\n"
     ]
    }
   ],
   "source": [
    "print important_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026982833380728453"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold(10, rfR, train[important_feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
