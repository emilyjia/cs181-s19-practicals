{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import util\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feats(ffs, direc=\"train\", global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      ffs are a list of feature-functions.\n",
    "      direc is a directory containing xml files (expected to be train or test).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that\n",
    "      the columns of the test matrix align correctly.\n",
    "\n",
    "    returns:\n",
    "      a sparse design matrix, a dict mapping features to column-numbers,\n",
    "      a vector of target classes, and a list of system-call-history ids in order\n",
    "      of their rows in the design matrix.\n",
    "\n",
    "      Note: the vector of target classes returned will contain the true indices of the\n",
    "      target classes on the training data, but will contain only -1's on the test\n",
    "      data\n",
    "    \"\"\"\n",
    "    fds = [] # list of feature dicts\n",
    "    classes = []\n",
    "    ids = []\n",
    "    #x = os.listdir(direc)[1:]\n",
    "    for datafile in os.listdir(direc):\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str,clazz = datafile.split('.')[:2]\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(util.malware_classes.index(clazz))\n",
    "        except ValueError:\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "        rowfd = {}\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        # accumulate features\n",
    "        [rowfd.update(ff(tree)) for ff in ffs]\n",
    "        fds.append(rowfd)\n",
    "\n",
    "    X,feat_dict = make_design_mat(fds,global_feat_dict)\n",
    "    return X, feat_dict, np.array(classes), ids\n",
    "\n",
    "\n",
    "def make_design_mat(fds, global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      fds is a list of feature dicts (one for each row).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that\n",
    "      the columns of the test matrix align correctly.\n",
    "\n",
    "    returns:\n",
    "        a sparse NxD design matrix, where N == len(fds) and D is the number of\n",
    "        the union of features defined in any of the fds\n",
    "    \"\"\"\n",
    "    if global_feat_dict is None:\n",
    "        all_feats = set()\n",
    "        [all_feats.update(list(fd.keys())) for fd in fds]\n",
    "        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])\n",
    "    else:\n",
    "        feat_dict = global_feat_dict\n",
    "\n",
    "    cols = []\n",
    "    rows = []\n",
    "    data = []\n",
    "    for i in range(len(fds)):\n",
    "        temp_cols = []\n",
    "        temp_data = []\n",
    "        for feat,val in list(fds[i].items()):\n",
    "            try:\n",
    "                # update temp_cols iff update temp_data\n",
    "                temp_cols.append(feat_dict[feat])\n",
    "                temp_data.append(val)\n",
    "            except KeyError as ex:\n",
    "                if global_feat_dict is not None:\n",
    "                    pass  # new feature in test data; nbd\n",
    "                else:\n",
    "                    raise ex\n",
    "\n",
    "        # all fd's features in the same row\n",
    "        k = len(temp_cols)\n",
    "        cols.extend(temp_cols)\n",
    "        data.extend(temp_data)\n",
    "        rows.extend([i]*k)\n",
    "\n",
    "    assert len(cols) == len(rows) and len(rows) == len(data)\n",
    "\n",
    "\n",
    "    X = sparse.csr_matrix((np.array(data),\n",
    "                   (np.array(rows), np.array(cols))),\n",
    "                   shape=(len(fds), len(feat_dict)))\n",
    "    return X, feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_reasons(tree):\n",
    "    c = Counter()\n",
    "    for el in tree.iter():\n",
    "        if el.tag == \"process\":\n",
    "            c[\"term\" + el.attrib[\"terminationreason\"]] += 1\n",
    "            c[\"start\" + el.attrib[\"startreason\"]] += 1\n",
    "            c[el.attrib[\"executionstatus\"]] += 1\n",
    "    return c\n",
    "\n",
    "def count_all_flags(tree):\n",
    "    c = Counter()\n",
    "    for el in tree.iter():\n",
    "        if el.attrib.get(\"flags\") == None:\n",
    "            continue\n",
    "        else:\n",
    "            c[el.attrib[\"flags\"]] += 1\n",
    "    return c\n",
    "\n",
    "def first_last_system_call_feats(tree):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      tree is an xml.etree.ElementTree object\n",
    "    returns:\n",
    "      a dictionary mapping 'first_call-x' to 1 if x was the first system call\n",
    "      made, and 'last_call-y' to 1 if y was the last system call made.\n",
    "      (in other words, it returns a dictionary indicating what the first and\n",
    "      last system calls made by an executable were.)\n",
    "    \"\"\"\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    first = True # is this the first system call\n",
    "    last_call = None # keep track of last call we've seen\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "            if first:\n",
    "                c[\"first_call-\"+el.tag] = 1\n",
    "                first = False\n",
    "            last_call = el.tag  # update last call seen\n",
    "\n",
    "    # finally, mark last call seen\n",
    "    c[\"last_call-\"+last_call] = 1\n",
    "    return c\n",
    "\n",
    "def system_call_count_feats(tree):\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "        elif in_all_section:\n",
    "            c[el.tag] += 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffs = [first_last_system_call_feats, system_call_count_feats, count_all_reasons, count_all_flags]\n",
    "X_train, global_feat_dict, t_train, train_ids = extract_feats(ffs, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=50, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [5, 10, 25, None], 'min_samples_split': [2, 5, 10, 15, 20], 'min_samples_leaf': [1, 5, 10, 15, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_depth': [5, 10, 25, None],\n",
    "          'min_samples_split': [2, 5, 10, 15, 20],\n",
    "          'min_samples_leaf': [1, 5, 10, 15, 20]}\n",
    "          #'max_features': ['auto', None]}\n",
    "rfc = RandomForestClassifier(n_estimators=500, random_state=50)\n",
    "gs = GridSearchCV(rfc, params, n_jobs=-1, scoring='accuracy', cv=4, verbose=3)\n",
    "gs.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2},\n",
       " 0.8956578094620868)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=50, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [15, 25, 45, 65, None], 'max_features': ['auto', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params2 = {'max_depth': [15, 25, 45, 65, None],\n",
    "           'max_features': ['auto', None]}\n",
    "gs2 = GridSearchCV(rfc, params2, n_jobs=-1, scoring='accuracy', cv=4, verbose=3)\n",
    "gs2.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 45, 'max_features': 'auto'}, 0.8924173687621516)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_params_, gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "[CV] max_depth=35 ....................................................\n",
      "[CV] max_depth=35 ....................................................\n",
      "[CV] max_depth=35 ....................................................\n",
      "[CV] max_depth=35 ....................................................\n",
      "[CV] ........................... max_depth=35, score=0.887306 -   7.8s\n",
      "[CV] max_depth=45 ....................................................\n",
      "[CV] ........................... max_depth=35, score=0.880463 -   7.9s\n",
      "[CV] max_depth=45 ....................................................\n",
      "[CV] ........................... max_depth=35, score=0.898570 -   8.2s\n",
      "[CV] max_depth=45 ....................................................\n",
      "[CV] ........................... max_depth=35, score=0.894394 -   8.3s\n",
      "[CV] max_depth=45 ....................................................\n",
      "[CV] ........................... max_depth=45, score=0.887306 -   7.2s\n",
      "[CV] max_depth=55 ....................................................\n",
      "[CV] ........................... max_depth=45, score=0.881748 -   7.6s\n",
      "[CV] max_depth=55 ....................................................\n",
      "[CV] ........................... max_depth=45, score=0.898570 -   7.6s\n",
      "[CV] max_depth=55 ....................................................\n",
      "[CV] ........................... max_depth=45, score=0.893090 -   7.7s\n",
      "[CV] max_depth=55 ....................................................\n",
      "[CV] ........................... max_depth=55, score=0.886010 -   7.3s\n",
      "[CV] ........................... max_depth=55, score=0.879177 -   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:   22.7s remaining:    4.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................... max_depth=55, score=0.899870 -   7.2s\n",
      "[CV] ........................... max_depth=55, score=0.894394 -   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 35}, 0.890149060272197)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params3 = {'max_depth': [35, 45, 55]}\n",
    "gs3 = GridSearchCV(rfc, params3, n_jobs=-1, scoring='accuracy', cv=4, verbose=3)\n",
    "gs3.fit(X_train, t_train)\n",
    "gs3.best_params_, gs3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
